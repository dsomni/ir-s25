{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93cf8ab1",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 31\u001b[0m\n\u001b[0;32m     23\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# faithfulness,       # Measures if the answer is supported by the context\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# answer_relevancy,   # Measures how relevant the answer is to the question\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     context_recall,     \u001b[38;5;66;03m# Measures if all relevant information is retrieved\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# context_precision   # Measures if the retrieved context is relevant\u001b[39;00m\n\u001b[0;32m     28\u001b[0m ]\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Run the evaluation\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\ragas\\_analytics.py:227\u001b[0m, in \u001b[0;36mtrack_was_completed.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m    226\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m--> 227\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\ragas\\evaluation.py:198\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(metric, MetricWithLLM) \u001b[38;5;129;01mand\u001b[39;00m metric\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m llm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m         llm \u001b[38;5;241m=\u001b[39m \u001b[43mllm_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m     metric\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;241m=\u001b[39m llm\n\u001b[0;32m    200\u001b[0m     llm_changed\u001b[38;5;241m.\u001b[39mappend(i)\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py:416\u001b[0m, in \u001b[0;36mllm_factory\u001b[1;34m(model, run_config, default_headers, base_url)\u001b[0m\n\u001b[0;32m    413\u001b[0m     default_headers \u001b[38;5;241m=\u001b[39m helicone_config\u001b[38;5;241m.\u001b[39mdefault_headers()\n\u001b[0;32m    414\u001b[0m     base_url \u001b[38;5;241m=\u001b[39m helicone_config\u001b[38;5;241m.\u001b[39mbase_url\n\u001b[1;32m--> 416\u001b[0m openai_model \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LangchainLLMWrapper(openai_model, run_config)\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:130\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:625\u001b[0m, in \u001b[0;36mBaseChatOpenAI.validate_environment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(\n\u001b[0;32m    622\u001b[0m             proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy, verify\u001b[38;5;241m=\u001b[39mglobal_ssl_context\n\u001b[0;32m    623\u001b[0m         )\n\u001b[0;32m    624\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\openai\\_client.py:124\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    122\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    126\u001b[0m     )\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import context_precision, context_recall\n",
    "\n",
    "# Sample data - this would typically come from your RAG pipeline\n",
    "data = {\n",
    "    \"question\": [\"What is the capital of France?\", \"Who wrote 'To Kill a Mockingbird'?\"],\n",
    "    \"answer\": [\"Paris\", \"Harper Lee\"],\n",
    "    \"contexts\": [\n",
    "        [\n",
    "            \"France is a country in Europe. Its capital is Paris.\",\n",
    "            \"Paris is known as the city of love.\",\n",
    "        ],\n",
    "        [\n",
    "            \"'To Kill a Mockingbird' was written by Harper Lee and published in 1960.\",\n",
    "            \"Harper Lee was an American novelist.\",\n",
    "        ],\n",
    "    ],\n",
    "    \"ground_truth\": [\n",
    "        \"The capital of France is Paris.\",\n",
    "        \"The author of 'To Kill a Mockingbird' is Harper Lee.\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "# Define the metrics you want to evaluate\n",
    "metrics = [\n",
    "    # faithfulness,       # Measures if the answer is supported by the context\n",
    "    # answer_relevancy,   # Measures how relevant the answer is to the question\n",
    "    context_recall,  # Measures if all relevant information is retrieved\n",
    "    # context_precision   # Measures if the retrieved context is relevant\n",
    "]\n",
    "\n",
    "# Run the evaluation\n",
    "result = evaluate(\n",
    "    dataset=dataset,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b5bec19",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class CustomAnswerRelevancy without an implementation for abstract method 'init'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m overlap\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m custom_metrics \u001b[38;5;241m=\u001b[39m [\u001b[43mCustomAnswerRelevancy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m     24\u001b[0m result \u001b[38;5;241m=\u001b[39m evaluate(dataset, metrics\u001b[38;5;241m=\u001b[39mcustom_metrics)\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't instantiate abstract class CustomAnswerRelevancy without an implementation for abstract method 'init'"
     ]
    }
   ],
   "source": [
    "from ragas.metrics.base import Metric\n",
    "\n",
    "\n",
    "class CustomAnswerRelevancy(Metric):\n",
    "    name = \"custom_answer_relevancy\"\n",
    "    batch_size = 15\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def score(self, row):\n",
    "        # Implement your own relevancy scoring logic\n",
    "        question = row[\"question\"].lower()\n",
    "        answer = row[\"answer\"].lower()\n",
    "\n",
    "        # Simple word overlap as example - replace with better logic\n",
    "        q_words = set(question.split())\n",
    "        a_words = set(answer.split())\n",
    "        overlap = len(q_words & a_words) / len(q_words) if q_words else 0\n",
    "        return overlap\n",
    "\n",
    "\n",
    "# Usage\n",
    "custom_metrics = [CustomAnswerRelevancy()]\n",
    "result = evaluate(dataset, metrics=custom_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3826164",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_dict(data)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Run fully local evaluation\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Print formatted results\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRAGAS Evaluation Results (100\u001b[39m\u001b[38;5;132;01m% Lo\u001b[39;00m\u001b[38;5;124mcal):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\ragas\\_analytics.py:227\u001b[0m, in \u001b[0;36mtrack_was_completed.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m    226\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m--> 227\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\ragas\\evaluation.py:198\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(metric, MetricWithLLM) \u001b[38;5;129;01mand\u001b[39;00m metric\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m llm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m         llm \u001b[38;5;241m=\u001b[39m \u001b[43mllm_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m     metric\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;241m=\u001b[39m llm\n\u001b[0;32m    200\u001b[0m     llm_changed\u001b[38;5;241m.\u001b[39mappend(i)\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py:416\u001b[0m, in \u001b[0;36mllm_factory\u001b[1;34m(model, run_config, default_headers, base_url)\u001b[0m\n\u001b[0;32m    413\u001b[0m     default_headers \u001b[38;5;241m=\u001b[39m helicone_config\u001b[38;5;241m.\u001b[39mdefault_headers()\n\u001b[0;32m    414\u001b[0m     base_url \u001b[38;5;241m=\u001b[39m helicone_config\u001b[38;5;241m.\u001b[39mbase_url\n\u001b[1;32m--> 416\u001b[0m openai_model \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LangchainLLMWrapper(openai_model, run_config)\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:130\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:625\u001b[0m, in \u001b[0;36mBaseChatOpenAI.validate_environment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(\n\u001b[0;32m    622\u001b[0m             proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy, verify\u001b[38;5;241m=\u001b[39mglobal_ssl_context\n\u001b[0;32m    623\u001b[0m         )\n\u001b[0;32m    624\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\openai\\_client.py:124\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    122\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    126\u001b[0m     )\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import List\n",
    "\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_relevancy, answer_similarity, context_recall\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "class LocalEmbeddings:\n",
    "    \"\"\"Fully local embedding implementation\"\"\"\n",
    "\n",
    "    def __init__(self, model_name=\"BAAI/bge-small-en-v1.5\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self.model.encode(texts, normalize_embeddings=True).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.model.encode(text, normalize_embeddings=True).tolist()\n",
    "\n",
    "    async def aembed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return await asyncio.get_event_loop().run_in_executor(\n",
    "            None, self.embed_documents, texts\n",
    "        )\n",
    "\n",
    "    async def aembed_query(self, text: str) -> List[float]:\n",
    "        return await asyncio.get_event_loop().run_in_executor(\n",
    "            None, self.embed_query, text\n",
    "        )\n",
    "\n",
    "\n",
    "# Initialize local components\n",
    "local_embeddings = LocalEmbeddings()\n",
    "\n",
    "# Select metrics that can run purely locally\n",
    "metrics = [answer_relevancy, context_precision, context_recall, answer_similarity]\n",
    "\n",
    "# Configure metrics to be fully local\n",
    "for metric in metrics:\n",
    "    # Remove any LLM dependencies\n",
    "    if hasattr(metric, \"llm\"):\n",
    "        metric.llm = None\n",
    "    # Set local embeddings\n",
    "    if hasattr(metric, \"embedding\"):\n",
    "        metric.embedding = local_embeddings\n",
    "    # Disable any OpenAI fallbacks\n",
    "    if hasattr(metric, \"api_key\"):\n",
    "        metric.api_key = \"\"\n",
    "\n",
    "# Sample evaluation data\n",
    "data = {\n",
    "    \"question\": [\"What is the capital of France?\"],\n",
    "    \"answer\": [\"Paris\"],\n",
    "    \"contexts\": [[\"France is a country in Europe. Its capital is Paris.\"]],\n",
    "    \"ground_truth\": [\"The capital of France is Paris.\"],\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "# Run fully local evaluation\n",
    "result = evaluate(\n",
    "    dataset=dataset,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "# Print formatted results\n",
    "print(\"\\nRAGAS Evaluation Results (100% Local):\")\n",
    "for metric_name, score in result.items():\n",
    "    print(f\"{metric_name.replace('_', ' ').title():<20} {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ffa697",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_dict(data)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRAGAS Evaluation Results (100\u001b[39m\u001b[38;5;132;01m% Lo\u001b[39;00m\u001b[38;5;124mcal):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\ragas\\_analytics.py:227\u001b[0m, in \u001b[0;36mtrack_was_completed.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m    226\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m--> 227\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\ragas\\evaluation.py:198\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(metric, MetricWithLLM) \u001b[38;5;129;01mand\u001b[39;00m metric\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m llm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m         llm \u001b[38;5;241m=\u001b[39m \u001b[43mllm_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m     metric\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;241m=\u001b[39m llm\n\u001b[0;32m    200\u001b[0m     llm_changed\u001b[38;5;241m.\u001b[39mappend(i)\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py:416\u001b[0m, in \u001b[0;36mllm_factory\u001b[1;34m(model, run_config, default_headers, base_url)\u001b[0m\n\u001b[0;32m    413\u001b[0m     default_headers \u001b[38;5;241m=\u001b[39m helicone_config\u001b[38;5;241m.\u001b[39mdefault_headers()\n\u001b[0;32m    414\u001b[0m     base_url \u001b[38;5;241m=\u001b[39m helicone_config\u001b[38;5;241m.\u001b[39mbase_url\n\u001b[1;32m--> 416\u001b[0m openai_model \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LangchainLLMWrapper(openai_model, run_config)\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:130\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:625\u001b[0m, in \u001b[0;36mBaseChatOpenAI.validate_environment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(\n\u001b[0;32m    622\u001b[0m             proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy, verify\u001b[38;5;241m=\u001b[39mglobal_ssl_context\n\u001b[0;32m    623\u001b[0m         )\n\u001b[0;32m    624\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\openai\\_client.py:124\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    122\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    126\u001b[0m     )\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_similarity, context_precision, context_recall\n",
    "\n",
    "\n",
    "class LocalEmbeddings:\n",
    "    \"\"\"Fully local embedding implementation\"\"\"\n",
    "\n",
    "    def __init__(self, model_name=\"BAAI/bge-small-en-v1.5\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self.model.encode(texts, normalize_embeddings=True).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.model.encode(text, normalize_embeddings=True).tolist()\n",
    "\n",
    "    async def aembed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return await asyncio.get_event_loop().run_in_executor(\n",
    "            None, self.embed_documents, texts\n",
    "        )\n",
    "\n",
    "    async def aembed_query(self, text: str) -> List[float]:\n",
    "        return await asyncio.get_event_loop().run_in_executor(\n",
    "            None, self.embed_query, text\n",
    "        )\n",
    "\n",
    "\n",
    "# Initialize local embedding model\n",
    "local_embeddings = LocalEmbeddings()\n",
    "\n",
    "# Patch the embedding model into the metrics\n",
    "metrics = [context_precision, context_recall, answer_similarity]\n",
    "for metric in metrics:\n",
    "    if hasattr(metric, \"embedding\"):\n",
    "        setattr(metric, \"embedding\", local_embeddings)\n",
    "    if hasattr(metric, \"llm\"):\n",
    "        setattr(metric, \"llm\", None)\n",
    "    if hasattr(metric, \"api_key\"):\n",
    "        setattr(metric, \"api_key\", \"\")\n",
    "\n",
    "# Sample data for evaluation\n",
    "data = {\n",
    "    \"question\": [\"What is the capital of France?\"],\n",
    "    \"answer\": [\"Paris\"],\n",
    "    \"contexts\": [[\"France is a country in Europe. Its capital is Paris.\"]],\n",
    "    \"ground_truth\": [\"The capital of France is Paris.\"],\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "# Evaluate\n",
    "result = evaluate(dataset=dataset, metrics=metrics)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nRAGAS Evaluation Results (100% Local):\")\n",
    "for metric_name, score in result.items():\n",
    "    print(f\"{metric_name.replace('_', ' ').title():<20} {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266b631d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai.resources'; 'openai' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 55\u001b[0m\n\u001b[0;32m     47\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the capital of France?\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParis\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontexts\u001b[39m\u001b[38;5;124m\"\u001b[39m: [[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrance is a country in Europe. Its capital is Paris.\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mground_truth\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe capital of France is Paris.\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     52\u001b[0m }\n\u001b[0;32m     53\u001b[0m dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_dict(data)\n\u001b[1;32m---> 55\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRAGAS Evaluation Results (100\u001b[39m\u001b[38;5;132;01m% Lo\u001b[39;00m\u001b[38;5;124mcal):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric_name, score \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\ragas\\_analytics.py:227\u001b[0m, in \u001b[0;36mtrack_was_completed.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m    226\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m--> 227\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\ragas\\evaluation.py:198\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(metric, MetricWithLLM) \u001b[38;5;129;01mand\u001b[39;00m metric\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m llm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m         llm \u001b[38;5;241m=\u001b[39m \u001b[43mllm_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m     metric\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;241m=\u001b[39m llm\n\u001b[0;32m    200\u001b[0m     llm_changed\u001b[38;5;241m.\u001b[39mappend(i)\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py:416\u001b[0m, in \u001b[0;36mllm_factory\u001b[1;34m(model, run_config, default_headers, base_url)\u001b[0m\n\u001b[0;32m    413\u001b[0m     default_headers \u001b[38;5;241m=\u001b[39m helicone_config\u001b[38;5;241m.\u001b[39mdefault_headers()\n\u001b[0;32m    414\u001b[0m     base_url \u001b[38;5;241m=\u001b[39m helicone_config\u001b[38;5;241m.\u001b[39mbase_url\n\u001b[1;32m--> 416\u001b[0m openai_model \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LangchainLLMWrapper(openai_model, run_config)\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:130\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:626\u001b[0m, in \u001b[0;36mBaseChatOpenAI.validate_environment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    624\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mOpenAI(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msync_specific)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241m.\u001b[39mcompletions\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_async_client:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\functools.py:995\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, instance, owner)\u001b[0m\n\u001b[0;32m    993\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[1;32m--> 995\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    997\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[1;32mc:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\openai\\_client.py:165\u001b[0m, in \u001b[0;36mOpenAI.chat\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchat\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Chat:\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresources\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chat\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Chat(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openai.resources'; 'openai' is not a package"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import types\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# Prevent openai from being loaded by any part of RAGAS\n",
    "sys.modules[\"openai\"] = types.ModuleType(\"openai\")\n",
    "sys.modules[\"openai\"].OpenAI = None\n",
    "sys.modules[\"openai\"].api_key = \"\"\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_similarity, context_precision, context_recall\n",
    "\n",
    "\n",
    "class LocalEmbeddings:\n",
    "    def __init__(self, model_name=\"BAAI/bge-small-en-v1.5\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self.model.encode(texts, normalize_embeddings=True).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.model.encode(text, normalize_embeddings=True).tolist()\n",
    "\n",
    "    async def aembed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return await asyncio.get_event_loop().run_in_executor(\n",
    "            None, self.embed_documents, texts\n",
    "        )\n",
    "\n",
    "    async def aembed_query(self, text: str) -> List[float]:\n",
    "        return await asyncio.get_event_loop().run_in_executor(\n",
    "            None, self.embed_query, text\n",
    "        )\n",
    "\n",
    "\n",
    "local_embeddings = LocalEmbeddings()\n",
    "\n",
    "metrics = [context_precision, context_recall, answer_similarity]\n",
    "for metric in metrics:\n",
    "    if hasattr(metric, \"embedding\"):\n",
    "        metric.embedding = local_embeddings\n",
    "    if hasattr(metric, \"llm\"):\n",
    "        metric.llm = None\n",
    "\n",
    "data = {\n",
    "    \"question\": [\"What is the capital of France?\"],\n",
    "    \"answer\": [\"Paris\"],\n",
    "    \"contexts\": [[\"France is a country in Europe. Its capital is Paris.\"]],\n",
    "    \"ground_truth\": [\"The capital of France is Paris.\"],\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "result = evaluate(dataset=dataset, metrics=metrics)\n",
    "\n",
    "print(\"\\nRAGAS Evaluation Results (100% Local):\")\n",
    "for metric_name, score in result.items():\n",
    "    print(f\"{metric_name.replace('_', ' ').title():<20} {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01062a55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
