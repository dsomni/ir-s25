{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5575255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from sklearn.neighbors import BallTree\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "from utils import from_current_file, load\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b97b0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTEmbedder:\n",
    "    def __init__(\n",
    "        self, model_name=\"sentence-transformers/msmarco-bert-base-dot-v5\", device=DEVICE\n",
    "    ):\n",
    "        self.device = device or \"cpu\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.do_lower_case = getattr(self.tokenizer, \"do_lower_case\", False)\n",
    "\n",
    "    def text_to_embedding(self, texts, pooling=\"mean\", normalize=False):\n",
    "        is_single = isinstance(texts, str)\n",
    "        texts = [texts] if is_single else texts\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "        if pooling == \"mean\":\n",
    "            mask = inputs[\"attention_mask\"].unsqueeze(-1)\n",
    "            embeddings = (outputs.last_hidden_state * mask).sum(1) / mask.sum(1).clamp(\n",
    "                min=1e-9\n",
    "            )\n",
    "        elif pooling == \"cls\":\n",
    "            embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid pooling method\")\n",
    "\n",
    "        if normalize:\n",
    "            embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "        return embeddings.cpu().numpy()[0] if is_single else embeddings.cpu().numpy()\n",
    "\n",
    "\n",
    "def batch(iterable, batch_size):\n",
    "    all_batches = []\n",
    "    current_batch = []\n",
    "\n",
    "    for item in iterable:\n",
    "        current_batch.append(item)\n",
    "        if len(current_batch) == batch_size:\n",
    "            all_batches.append(current_batch)\n",
    "            current_batch = []\n",
    "\n",
    "    if current_batch:  # Add the last partial batch\n",
    "        all_batches.append(current_batch)\n",
    "\n",
    "    return all_batches\n",
    "\n",
    "\n",
    "class BERTBallTree:\n",
    "    def __init__(\n",
    "        self,\n",
    "        index_dir: str = \"../data/embedding_directory\",\n",
    "        documents_dir: str = \"../data/scrapped/class_data_function__1_1\",\n",
    "        embedder=None,\n",
    "        metric=\"euclidean\",\n",
    "        leaf_size=1,\n",
    "        tree_name=\"tree\",\n",
    "        force=False,\n",
    "    ):\n",
    "        self._index_dir = from_current_file(index_dir)\n",
    "        self._documents_dir = from_current_file(documents_dir)\n",
    "        self.embedder = embedder or BERTEmbedder()\n",
    "        self.metric = metric\n",
    "        self.leaf_size = leaf_size\n",
    "        self.tree = None\n",
    "        self.tree_name = tree_name\n",
    "        self.documents: dict[int, str] = {}\n",
    "\n",
    "        if force or not os.path.exists(self._index_dir):\n",
    "            print(\"Tree is not found, creating new...\")\n",
    "            if force:\n",
    "                try:\n",
    "                    shutil.rmtree(self._index_dir)\n",
    "                except FileNotFoundError:\n",
    "                    pass\n",
    "            os.mkdir(path=self._index_dir)\n",
    "            self.build_tree()\n",
    "            print(\"Complete!\")\n",
    "\n",
    "        self.load_tree()\n",
    "\n",
    "    def build_tree(self):\n",
    "        sentences = []\n",
    "        for document_id, filename in enumerate(os.listdir(self._documents_dir)):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                with open(\n",
    "                    os.path.join(self._documents_dir, filename), \"r\", encoding=\"utf-8\"\n",
    "                ) as f:\n",
    "                    text = f.read()\n",
    "                    self.documents[document_id] = filename[:-4]\n",
    "                    sentences.append(text)\n",
    "\n",
    "        embeddings = []\n",
    "        for b in tqdm(batch(sentences, 64)):\n",
    "            batch_embeddings = self.embedder.text_to_embedding(\n",
    "                b, pooling=\"mean\", normalize=True\n",
    "            )\n",
    "            embeddings.extend(batch_embeddings)\n",
    "        self.tree = BallTree(embeddings, metric=self.metric, leaf_size=self.leaf_size)\n",
    "        self.save_tree()\n",
    "\n",
    "    def query(self, query_text, k=5, return_distances=False):\n",
    "        \"\"\"\n",
    "        Query the Ball Tree for nearest neighbors.\n",
    "\n",
    "        Args:\n",
    "            query_text: The query text string\n",
    "            k: Number of nearest neighbors to return\n",
    "            return_distances: Whether to return distances along with results\n",
    "\n",
    "        Returns:\n",
    "            If return_distances is False: list of nearest texts\n",
    "            If return_distances is True: tuple of (texts, distances)\n",
    "        \"\"\"\n",
    "        if self.tree is None:\n",
    "            raise ValueError(\"Ball Tree has not been built yet. Call build_tree() first.\")\n",
    "\n",
    "        # Get embedding for the query text\n",
    "        query_embedding = self.embedder.text_to_embedding(\n",
    "            query_text, pooling=\"mean\", normalize=True\n",
    "        ).reshape(1, -1)\n",
    "\n",
    "        # Query the tree\n",
    "        distances, indices = self.tree.query(query_embedding, k=k)\n",
    "\n",
    "        # Get the corresponding texts\n",
    "        results = []\n",
    "        for indice in indices[0]:\n",
    "            results.append(self.documents[indice])\n",
    "\n",
    "        if return_distances:\n",
    "            return results, distances[0]\n",
    "        return results\n",
    "\n",
    "    def save_tree(self):\n",
    "        \"\"\"Save the Ball Tree and associated data to disk.\"\"\"\n",
    "        import joblib\n",
    "\n",
    "        data = {\n",
    "            \"tree\": self.tree,\n",
    "            \"documents\": self.documents,\n",
    "        }\n",
    "        joblib.dump(data, os.path.join(self._index_dir, self.tree_name))\n",
    "\n",
    "    def load_tree(self):\n",
    "        \"\"\"Load a saved Ball Tree from disk.\"\"\"\n",
    "        import joblib\n",
    "\n",
    "        data = joblib.load(os.path.join(self._index_dir, self.tree_name))\n",
    "        self.tree = data[\"tree\"]\n",
    "        self.documents = data[\"documents\"]\n",
    "\n",
    "\n",
    "# Initialize and build the tree\n",
    "ball_tree = BERTBallTree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2263ba",
   "metadata": {},
   "source": [
    "### ADD INDEXER/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed98b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "from g4f.client import Client\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "\n",
    "class RAG:\n",
    "    folder_path = \"../data/scrapped/class_data_function__1_1\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = Client()\n",
    "        model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id, device_map=\"cuda\", torch_dtype=\"auto\", trust_remote_code=True\n",
    "        )\n",
    "\n",
    "    def generate_stream(self, question: str, model: str, k: int = 10):\n",
    "        res, context = self._retrive_docs(question, k)\n",
    "        prompt = (\n",
    "            \"You're a Python expert. Suppose all the documentation information you know is provided in context section. \"\n",
    "            \"Answer on the question as usual but take technical information only from context. \"\n",
    "            'If there is no answer in the context, say, \"I can\\'t find the answer in the Python documentation\"\\n'\n",
    "            \"Highlight cited passages or provide “show sources” toggles ONLY FROM CONTEXT\\n\"\n",
    "            \"NO PYTHON CODE EXAMPLES!\\n\"\n",
    "            \"NO PROMPT REPETITION IN ANSWER!\\n\"\n",
    "            \"NO EXAMPLES!\\n\"\n",
    "            \"NO ADDITIONAL EXPLANATIONS!\\n\"\n",
    "            'If question is unrealated to python documentation, just answer \"Question is unrelated\"\\n'\n",
    "            \"\\nContext:\\n\"\n",
    "            f\"{'\\n\\n'.join([f'{idx + 1}. {c}' for idx, c in enumerate(context)])}\\n\"\n",
    "            f\"\\nQuestion: {question}\\n\"\n",
    "            f\"\\nResponse (with reference to the source [1-{k}]):\\n\"\n",
    "        )\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "        yield (\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"type\": \"proposals\",\n",
    "                    \"data\": [{\"document\": x[0], \"score\": x[1]} for x in res],\n",
    "                }\n",
    "            )\n",
    "            + \"\\n\\n\"\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                stream=True,\n",
    "                verbose=False,\n",
    "                max_tokens=200,\n",
    "            )\n",
    "\n",
    "            for chunk in response:\n",
    "                if chunk.choices[0].delta.content:\n",
    "                    yield (\n",
    "                        json.dumps(\n",
    "                            {\"type\": \"chunk\", \"data\": chunk.choices[0].delta.content}\n",
    "                        )\n",
    "                        + \"\\n\\n\"\n",
    "                    )\n",
    "        except BaseException as e:\n",
    "            yield json.dumps({\"type\": \"error\", \"data\": str(e)}) + \"\\n\\n\"\n",
    "\n",
    "    def _retrive_docs(self, query_m: str, k):\n",
    "        results, distances = ball_tree.query(query_m, k, return_distances=True)\n",
    "        print(results, distances)\n",
    "\n",
    "        contents = []\n",
    "\n",
    "        for name in results:\n",
    "            content = load(os.path.join(self.folder_path, name + \".txt\"))\n",
    "\n",
    "            contents.append(name + \"\\n\" + content)\n",
    "\n",
    "        return [results, distances], contents\n",
    "\n",
    "    def get_answer(self, question: str, model: str, local: bool = True, k: int = 10):\n",
    "        _, context = self._retrive_docs(question, k)\n",
    "\n",
    "        prompt = (\n",
    "            \"You're a Python expert. Suppose all the documentation information you know is provided in context section. \"\n",
    "            \"Answer on the question as usual but take technical information only from context. \"\n",
    "            'If there is no answer in the context, say, \"I can\\'t find the answer in the Python documentation\"\\n'\n",
    "            \"Highlight cited passages or provide “show sources” toggles ONLY FROM CONTEXT\\n\"\n",
    "            \"NO PYTHON CODE EXAMPLES!\\n\"\n",
    "            \"NO PROMPT REPETITION IN ANSWER!\\n\"\n",
    "            \"NO EXAMPLES!\\n\"\n",
    "            \"NO ADDITIONAL EXPLANATIONS!\\n\"\n",
    "            'If question is unrealated to python documentation, just answer \"Question is unrelated\"\\n'\n",
    "            \"\\nContext:\\n\"\n",
    "            f\"{'\\n\\n'.join([f'{idx + 1}. {c}' for idx, c in enumerate(context)])}\\n\"\n",
    "            f\"\\nQuestion: {question}\\n\"\n",
    "            f\"\\nResponse (with reference to the source [1-{k}]):\\n\"\n",
    "        )\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "        try:\n",
    "            if not local:\n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=model, messages=messages, web_search=False, stream=False\n",
    "                )\n",
    "                return response.choices[0].message.content, \"\"\n",
    "            else:\n",
    "                inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs, max_new_tokens=200, use_cache=False\n",
    "                )\n",
    "                return self.tokenizer.decode(outputs[0], skip_special_tokens=True), \"\"\n",
    "        except BaseException as e:\n",
    "            return \"\", str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3367be08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "rag_model = RAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56ac46ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['functools.singledispatchmethod', 'weakref.proxy', 'gc.enable', 'gc.collect', 'weakref.getweakrefcount'] [0.48139615 0.50007839 0.50009877 0.50047324 0.50269447]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Question is unrelated', '')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_model.get_answer(\"How to find goth gf\", model=\"evil\", k=5, local=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bca74bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['math.pow', 'cmath.sin', 'math.prod', 'math.perm', 'marshal.loads'] [0.40519656 0.44195419 0.44203956 0.46457629 0.46607111]\n",
      "The sine of z is returned by the cmath.sin function.\n",
      "\n",
      "Show sources: [2]\n"
     ]
    }
   ],
   "source": [
    "print(rag_model.get_answer(\"sin\", model=\"evil\", k=5, local=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16172267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['math.pow', 'cmath.sin', 'math.prod', 'math.perm', 'marshal.loads'] [0.40519656 0.44195419 0.44203956 0.46457629 0.46607111]\n",
      "You're a Python expert. Suppose all the documentation information you know is provided in context section. Answer on the question as usual but take technical information only from context. If there is no answer in the context, say, \"I can't find the answer in the Python documentation\"\n",
      "Highlight cited passages or provide “show sources” toggles ONLY FROM CONTEXT\n",
      "NO PYTHON CODE EXAMPLES!\n",
      "NO PROMPT REPETITION IN ANSWER!\n",
      "NO EXAMPLES!\n",
      "NO ADDITIONAL EXPLANATIONS!\n",
      "If question is unrealated to python documentation, just answer \"Question is unrelated\"\n",
      "\n",
      "Context:\n",
      "1. math.pow\n",
      "FUNCTION\n",
      "\n",
      "math.pow FROM math\n",
      "\n",
      "PARAMETERS\n",
      "x, y\n",
      "\n",
      "DESCRIPTION\n",
      "Return x raised to the power y.  Exceptional cases follow\n",
      "the IEEE 754 standard as far as possible.  In particular,\n",
      "pow(1.0, x) and pow(x, 0.0) always return 1.0, even\n",
      "when x is a zero or a NaN.  If both x and y are finite,\n",
      "x is negative, and y is not an integer then pow(x, y)\n",
      "is undefined, and raises ValueError.\n",
      "Unlike the built-in ** operator, math.pow() converts both\n",
      "its arguments to type float.  Use ** or the built-in\n",
      "pow() function for computing exact integer powers.\n",
      "Changed in version 3.11: The special cases pow(0.0, -inf) and pow(-0.0, -inf) were\n",
      "changed to return inf instead of raising ValueError,\n",
      "for consistency with IEEE 754.\n",
      "\n",
      "2. cmath.sin\n",
      "FUNCTION\n",
      "\n",
      "cmath.sin FROM cmath\n",
      "\n",
      "PARAMETERS\n",
      "z\n",
      "\n",
      "DESCRIPTION\n",
      "Return the sine of z.\n",
      "\n",
      "3. math.prod\n",
      "FUNCTION\n",
      "\n",
      "math.prod FROM math\n",
      "\n",
      "PARAMETERS\n",
      "iterable, *, start=1\n",
      "\n",
      "DESCRIPTION\n",
      "Calculate the product of all the elements in the input iterable.\n",
      "The default start value for the product is 1.\n",
      "When the iterable is empty, return the start value.  This function is\n",
      "intended specifically for use with numeric values and may reject\n",
      "non-numeric types.\n",
      "Added in version 3.8.\n",
      "\n",
      "4. math.perm\n",
      "FUNCTION\n",
      "\n",
      "math.perm FROM math\n",
      "\n",
      "PARAMETERS\n",
      "n, k=None\n",
      "\n",
      "DESCRIPTION\n",
      "Return the number of ways to choose k items from n items\n",
      "without repetition and with order.\n",
      "Evaluates to n! / (n - k)! when k <= n and evaluates\n",
      "to zero when k > n.\n",
      "If k is not specified or is None, then k defaults to n\n",
      "and the function returns n!.\n",
      "Raises TypeError if either of the arguments are not integers.\n",
      "Raises ValueError if either of the arguments are negative.\n",
      "Added in version 3.8.\n",
      "\n",
      "5. marshal.loads\n",
      "FUNCTION\n",
      "\n",
      "marshal.loads FROM marshal\n",
      "\n",
      "PARAMETERS\n",
      "bytes\n",
      "\n",
      "DESCRIPTION\n",
      "Convert the bytes-like object to a value.  If no valid value is found, raise\n",
      "EOFError, ValueError or TypeError.  Extra bytes in the\n",
      "input are ignored.\n",
      "Raises an auditing event marshal.loads with argument bytes.\n",
      "Changed in version 3.10: This call used to raise a code.__new__ audit event for each code object. Now\n",
      "it raises a single marshal.loads event for the entire load operation.\n",
      "\n",
      "Question: sin\n",
      "\n",
      "Response (with reference to the source [1-5]):\n",
      "\n",
      "cmath.sin\n",
      "\n",
      "Context:\n",
      "1. math.pow\n",
      "FUNCTION\n",
      "\n",
      "math.pow FROM math\n",
      "\n",
      "PARAMETERS\n",
      "x, y\n",
      "\n",
      "DESCRIPTION\n",
      "Return x raised to the power y.  Exceptional cases follow\n",
      "the IEEE 754 standard as far as possible.  In particular,\n",
      "pow(1.0, x) and pow(x, 0.0) always return 1.0, even\n",
      "when x is a zero or a NaN.  If both x and y are finite,\n",
      "x is negative, and y is not an integer then pow(x, y)\n",
      "is undefined, and raises ValueError.\n",
      "Unlike the built-in ** operator, math.pow() converts both\n",
      "its arguments to type float.  Use ** or the built-in\n",
      "pow() function for computing exact integer powers.\n",
      "Changed in version 3.11: The special\n"
     ]
    }
   ],
   "source": [
    "print(rag_model.get_answer(\"sin\", model=\"evil\", k=5, local=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d380b",
   "metadata": {},
   "source": [
    "- command-r\n",
    "- evil\n",
    "- qwen-2-72b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3e6b49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
