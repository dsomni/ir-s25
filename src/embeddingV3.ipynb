{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0297586",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T10:55:28.290589Z",
     "start_time": "2025-05-14T10:55:28.257542Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2ef590d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kiaver\\PycharmProjects\\ir-s25\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from sklearn.neighbors import BallTree\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "from utils import from_current_file\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# DEVICE = torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220586d53129cbbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T10:56:21.064614Z",
     "start_time": "2025-05-14T10:56:17.792802Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:35<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5711\n",
      "[2704  388 2705 2702 2655 4090  389 4091 2666 2664]\n",
      "Query: sin\n",
      "Top 3 results:\n",
      "- math.pow (distance: 0.4052)\n",
      "- cmath.sin (distance: 0.4420)\n",
      "- math.prod (distance: 0.4420)\n",
      "- math.perm (distance: 0.4646)\n",
      "- marshal.loads (distance: 0.4661)\n",
      "- stat.ST_ATIME (distance: 0.4671)\n",
      "- cmath.sinh (distance: 0.4679)\n",
      "- stat.ST_CTIME (distance: 0.4727)\n",
      "- math.comb (distance: 0.4744)\n",
      "- math.cbrt (distance: 0.4775)\n"
     ]
    }
   ],
   "source": [
    "class BERTEmbedder:\n",
    "    def __init__(\n",
    "        self, model_name=\"sentence-transformers/msmarco-bert-base-dot-v5\", device=DEVICE\n",
    "    ):\n",
    "        self.device = device or \"cpu\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.do_lower_case = getattr(self.tokenizer, \"do_lower_case\", False)\n",
    "\n",
    "    def text_to_embedding(self, texts, pooling=\"mean\", normalize=False):\n",
    "        is_single = isinstance(texts, str)\n",
    "        texts = [texts] if is_single else texts\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "        if pooling == \"mean\":\n",
    "            mask = inputs[\"attention_mask\"].unsqueeze(-1)\n",
    "            embeddings = (outputs.last_hidden_state * mask).sum(1) / mask.sum(1).clamp(\n",
    "                min=1e-9\n",
    "            )\n",
    "        elif pooling == \"cls\":\n",
    "            embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid pooling method\")\n",
    "\n",
    "        if normalize:\n",
    "            embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "        return embeddings.cpu().numpy()[0] if is_single else embeddings.cpu().numpy()\n",
    "\n",
    "\n",
    "def batch(iterable, batch_size):\n",
    "    all_batches = []\n",
    "    current_batch = []\n",
    "\n",
    "    for item in iterable:\n",
    "        current_batch.append(item)\n",
    "        if len(current_batch) == batch_size:\n",
    "            all_batches.append(current_batch)\n",
    "            current_batch = []\n",
    "\n",
    "    if current_batch:  # Add the last partial batch\n",
    "        all_batches.append(current_batch)\n",
    "\n",
    "    return all_batches\n",
    "\n",
    "\n",
    "class BERTBallTree:\n",
    "    def __init__(\n",
    "        self,\n",
    "        index_dir: str = \"../data/embedding_directory\",\n",
    "        documents_dir: str = \"../data/scrapped/class_data_function__1_1\",\n",
    "        top_similar: int = 10,\n",
    "        force: bool = False,\n",
    "        embedder=None,\n",
    "        metric=\"euclidean\",\n",
    "        leaf_size=1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the BERT Ball Tree.\n",
    "\n",
    "        Args:\n",
    "            embedder: Pre-initialized BERTEmbedder instance\n",
    "            metric: Distance metric for BallTree ('euclidean', 'cosine', etc.)\n",
    "            leaf_size: Affects the speed of queries and memory usage\n",
    "        \"\"\"\n",
    "        self._index_dir = from_current_file(index_dir)\n",
    "        self._documents_dir = from_current_file(documents_dir)\n",
    "        self.top_similar = top_similar\n",
    "        self.embedder = embedder or BERTEmbedder()\n",
    "        self.metric = metric\n",
    "        self.leaf_size = leaf_size\n",
    "        self.tree = None\n",
    "        self.texts = None\n",
    "        self.documents: dict[int, str] = {}\n",
    "\n",
    "    def build_tree(self):\n",
    "        \"\"\"\n",
    "        Build the Ball Tree from a list of texts.\n",
    "\n",
    "        Args:\n",
    "            texts: List of strings to index\n",
    "        \"\"\"\n",
    "        sentences = []\n",
    "        for document_id, filename in enumerate(os.listdir(self._documents_dir)):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                with open(\n",
    "                    os.path.join(self._documents_dir, filename), \"r\", encoding=\"utf-8\"\n",
    "                ) as f:\n",
    "                    text = f.read()\n",
    "                    self.documents[document_id] = filename[:-4]\n",
    "                    sentences.append(text)\n",
    "\n",
    "        embeddings = []\n",
    "        for b in tqdm(batch(sentences, 64)):\n",
    "            batch_embeddings = self.embedder.text_to_embedding(\n",
    "                b, pooling=\"mean\", normalize=True\n",
    "            )\n",
    "            embeddings.extend(batch_embeddings)\n",
    "        print(len(embeddings))\n",
    "        self.tree = BallTree(embeddings, metric=self.metric, leaf_size=self.leaf_size)\n",
    "\n",
    "    def query(self, query_text, k=5, return_distances=False):\n",
    "        \"\"\"\n",
    "        Query the Ball Tree for nearest neighbors.\n",
    "\n",
    "        Args:\n",
    "            query_text: The query text string\n",
    "            k: Number of nearest neighbors to return\n",
    "            return_distances: Whether to return distances along with results\n",
    "\n",
    "        Returns:\n",
    "            If return_distances is False: list of nearest texts\n",
    "            If return_distances is True: tuple of (texts, distances)\n",
    "        \"\"\"\n",
    "        if self.tree is None:\n",
    "            raise ValueError(\"Ball Tree has not been built yet. Call build_tree() first.\")\n",
    "\n",
    "        # Get embedding for the query text\n",
    "        query_embedding = self.embedder.text_to_embedding(\n",
    "            query_text, pooling=\"mean\", normalize=True\n",
    "        ).reshape(1, -1)\n",
    "\n",
    "        # Query the tree\n",
    "        distances, indices = self.tree.query(query_embedding, k=k)\n",
    "\n",
    "        # Get the corresponding texts\n",
    "        print(indices[0])\n",
    "        results = []\n",
    "        for indice in indices[0]:\n",
    "            results.append(self.documents[indice])\n",
    "\n",
    "        if return_distances:\n",
    "            return results, distances[0]\n",
    "        return results\n",
    "\n",
    "    def save_tree(self, filepath):\n",
    "        \"\"\"Save the Ball Tree and associated data to disk.\"\"\"\n",
    "        import joblib\n",
    "\n",
    "        data = {\n",
    "            \"texts\": self.texts,\n",
    "            \"tree\": self.tree,\n",
    "            \"metric\": self.metric,\n",
    "            \"leaf_size\": self.leaf_size,\n",
    "        }\n",
    "        joblib.dump(data, filepath)\n",
    "\n",
    "    @classmethod\n",
    "    def load_tree(cls, filepath, embedder=None):\n",
    "        \"\"\"Load a saved Ball Tree from disk.\"\"\"\n",
    "        import joblib\n",
    "\n",
    "        data = joblib.load(filepath)\n",
    "        instance = cls(\n",
    "            embedder=embedder, metric=data[\"metric\"], leaf_size=data[\"leaf_size\"]\n",
    "        )\n",
    "        instance.texts = data[\"texts\"]\n",
    "        instance.tree = data[\"tree\"]\n",
    "        return instance\n",
    "\n",
    "\n",
    "# Initialize and build the tree\n",
    "ball_tree = BERTBallTree()\n",
    "ball_tree.build_tree()\n",
    "\n",
    "# Query the tree\n",
    "query = \"sin\"\n",
    "results, distances = ball_tree.query(query, k=10, return_distances=True)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(\"Top 3 results:\")\n",
    "for text, dist in zip(results, distances):\n",
    "    print(f\"- {text} (distance: {dist:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c378f434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2702 2666 2668 2704 2699 2691 2679 2706 2664 2693]\n",
      "Query: math\n",
      "Top 3 results:\n",
      "- math.perm (distance: 0.4053)\n",
      "- math.comb (distance: 0.4101)\n",
      "- math.cos (distance: 0.4238)\n",
      "- math.pow (distance: 0.4260)\n",
      "- math.modf (distance: 0.4261)\n",
      "- math.isqrt (distance: 0.4286)\n",
      "- math.floor (distance: 0.4314)\n",
      "- math.radians (distance: 0.4337)\n",
      "- math.cbrt (distance: 0.4351)\n",
      "- math.ldexp (distance: 0.4401)\n"
     ]
    }
   ],
   "source": [
    "query = \"math\"\n",
    "results, distances = ball_tree.query(query, k=10, return_distances=True)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(\"Top 3 results:\")\n",
    "for text, dist in zip(results, distances):\n",
    "    print(f\"- {text} (distance: {dist:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa5a2609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2706  390 1133 1187 2687 2660 2681 5187 3052 5220]\n",
      "Query: sqrt\n",
      "Top 3 results:\n",
      "- math.radians (distance: 0.4383)\n",
      "- cmath.sqrt (distance: 0.4817)\n",
      "- decimal.Context.sqrt (distance: 0.4834)\n",
      "- decimal.Decimal.sqrt (distance: 0.4943)\n",
      "- math.isclose (distance: 0.5119)\n",
      "- math.asinh (distance: 0.5162)\n",
      "- math.frexp (distance: 0.5241)\n",
      "- unittest.IsolatedAsyncioTestCase.enterAsyncContext (distance: 0.5290)\n",
      "- os.CLONE_NEWIPC (distance: 0.5312)\n",
      "- unittest.mock.mock_open (distance: 0.5315)\n"
     ]
    }
   ],
   "source": [
    "query = \"sqrt\"\n",
    "results, distances = ball_tree.query(query, k=10, return_distances=True)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(\"Top 3 results:\")\n",
    "for text, dist in zip(results, distances):\n",
    "    print(f\"- {text} (distance: {dist:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "595327f7b3e82c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5059 5042 5049 5030 4988 5026 4993 5068 4986 5069]\n",
      "Query: turtle\n",
      "Top 3 results:\n",
      "- turtle.title (distance: 0.3896)\n",
      "- turtle.setup (distance: 0.4083)\n",
      "- turtle.shapetransform (distance: 0.4142)\n",
      "- turtle.resetscreen (distance: 0.4162)\n",
      "- turtle.forward (distance: 0.4169)\n",
      "- turtle.radians (distance: 0.4235)\n",
      "- turtle.getturtle (distance: 0.4242)\n",
      "- turtle.up (distance: 0.4262)\n",
      "- turtle.fillcolor (distance: 0.4293)\n",
      "- turtle.update (distance: 0.4297)\n"
     ]
    }
   ],
   "source": [
    "query = \"turtle\"\n",
    "results, distances = ball_tree.query(query, k=10, return_distances=True)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(\"Top 3 results:\")\n",
    "for text, dist in zip(results, distances):\n",
    "    print(f\"- {text} (distance: {dist:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9baae318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2699  385 3153 3320 3321 2702  739 3362 3351 2666]\n",
      "Query: pi\n",
      "Top 3 results:\n",
      "- math.modf (distance: 0.4330)\n",
      "- cmath.pi (distance: 0.4586)\n",
      "- os.getpriority (distance: 0.4877)\n",
      "- os.P_NOWAIT (distance: 0.4890)\n",
      "- os.P_NOWAITO (distance: 0.4949)\n",
      "- math.perm (distance: 0.4960)\n",
      "- curses.ACS_PI (distance: 0.4992)\n",
      "- os.SCHED_RESET_ON_FORK (distance: 0.5058)\n",
      "- os.scandir (distance: 0.5064)\n",
      "- math.comb (distance: 0.5071)\n"
     ]
    }
   ],
   "source": [
    "query = \"pi\"\n",
    "results, distances = ball_tree.query(query, k=10, return_distances=True)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(\"Top 3 results:\")\n",
    "for text, dist in zip(results, distances):\n",
    "    print(f\"- {text} (distance: {dist:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1604efbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
