# ğŸ“˜ PyFinder

**PyFinder** is a powerful application that enables fast, intelligent search through Python's built-in documentation using advanced retrieval methods.

> \[!IMPORTANT]
> ğŸ“„ We **highly recommend** reading [`README.md`](./README.md) to understand the structure of project and how to run it.

---

## ğŸ“‘ Table of Contents

- [ğŸ” Modes](#-modes)
- [âš™ï¸ Technology Stack](#ï¸-technology-stack)
  - [ğŸ§ª Backend](#-backend)
    - [ğŸ“˜ Selected Python libraries](#-selected-python-libraries)
  - [ğŸ¨ Frontend](#-frontend)
  - [ğŸ§  Models](#-models)
- [ğŸ§  System Design](#-system-design)
  - [ğŸ§© Workflows](#-workflows)
- [ğŸ§© Components](#-components)
  - [ğŸŒ¸ Bloom Filter](#-bloom-filter)
  - [ğŸ“ Norvig Spell Corrector](#-norvig-spell-corrector)
  - [ğŸ“š Indexer (Inverted Index)](#-indexer-inverted-index)
  - [ğŸ§¬ Indexer (LLM Embeddings + Ball Tree)](#-indexer-llm-embeddings--ball-tree)
  - [ğŸ¤– RAG (Retrieval-Augmented Generation)](#-rag-retrieval-augmented-generation)
- [ğŸš§ Challenges & Solutions](#-challenges--solutions)
- [ğŸŒŸ Feature Comparison](#-feature-comparison)

---

## ğŸ” Modes

**PyFinder** has two primary modes of operation:

- **Search Mode**
  Quickly find relevant documentation using one of two indexing approaches:

  - **Inverted Index**
  - **LLM Embeddings + Ball Tree**

- **Chat Mode (RAG)**
  Ask natural language questions and get intelligent, sourced answers via Retrieval-Augmented Generation (RAG) powered by LLMs.

---

## âš™ï¸ Technology Stack

### ğŸ§ª Backend

- **Python 3.12** â€” Primary language
- **FastAPI** â€” Web framework

#### ğŸ“˜ Selected Python libraries

- **NLTK** â€” Text processing
- **scikit-learn** â€” ML algorithms (e.g., Ball Tree)
- **PyTorch** â€” Neural network library
- **Transformers** â€” LLM models
- **g4f** â€” Free LLM API access (e.g., `evil`, `command-r`, `qwen`)
- **pybloom-live** â€” Probabilistic filtering (bad words)

### ğŸ¨ Frontend

- **Next.js** â€” React framework for UI

### ğŸ§  Models

- Hosted LLMs: `qwen-2-72b`, `qwen-2.5-coder-32b`,`gpt-4o`, `wizardlm-2-7b`, `wizardlm-2-8x22b`, `dolphin-2.6`, `dolphin-2.9`, `glm-4`, `evil`, `command-r`

- Local LLMs: [`arnir0/Tiny-LLM`](https://huggingface.co/arnir0/Tiny-LLM), [`sshleifer/tiny-gpt2`](https://huggingface.co/sshleifer/tiny-gpt2)
- Embedding Model: `sentence-transformers/all-MiniLM-L6-v2`

---

## ğŸ§  System Design

![System Architecture](./pictures/Flow_PyFinder.png)

### ğŸ§© Workflows

1. **Frontend â” Bloom** â€” Filters bad content
2. **Frontend â” Norvig** â€” Spell corrector
3. **Frontend â” Scraped Data** â€” Displays scraped docs
4. **Bloom â” RAG** â€” Sends clean query to RAG
5. **RAG â” Norvig** â€” Filters bad content
6. **Norvig â” Indexer** â€” Fetches relevant docs
7. **Indexer â” Scraped Data** â€” Retrieves matched files
8. **RAG â” LLM API** â€” Generates and returns LLM answer

---

## ğŸ§© Components

### ğŸŒ¸ Bloom Filter

#### 1. Bad Word List Aggregation

Sources merged from:

- [Google Profanity List](https://github.com/coffee-and-fun/google-profanity-words/tree/main)
- [LDNOOBW (English)](https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/blob/master/en)
- [LDNOOBW (Russian)](https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/blob/master/ru)

The merged document is [`data/bad_words/bad_words.txt`](./data/bad_words/bad_words.txt)

#### 2. Efficient Storage

- Uses `ScalableBloomFilter` (5000-word capacity, 0.1% false positive)
- Stores words and phrases (up to 5 words)

#### 3. Moderation Logic

- Scans individual and multi-word phrases
- Returns first match with offending term

#### Key Features

- Multi-language support
- Auto cache rebuild
- Configurable phrase length

---

### ğŸ“ Norvig Spell Corrector

[The original post](https://norvig.com/spell-correct.html)

#### 1. Text Preprocessing

- Removes stopwords
- Tokenizes lowercase words
- Strips non-ASCII characters

#### 2. Language Model

- Builds frequency model from cleaned docs
- Calculates word probabilities
- Supports precomputed edit dictionaries

#### 3. Suggestions

- Edit types: deletion, transposition, replacement, insertion
- Filters to valid words, returns most likely candidate

#### 4. Query Processing

- Retains punctuation
- Skips stopwords if configured

#### Optimizations

- Precomputed dictionaries for speed
- Stopword filtering for accuracy
- Tunable max edit distance

---

### ğŸ“š Indexer (Inverted Index)

#### 1. Indexing

- Maps words to documents
- Stores:
  - Word counts (TF)
  - Doc lengths (normalization)
  - Titles

#### 2. Search

- Uses Levenshtein distance
- Ranks using TF-IDF weighted by similarity:
  \[
  \text{Score} = \frac{1}{1 + \text{edit distance}}
  \]

#### 3. Fuzzy Matching

- Matches within edit distance
- Partial matches contribute based on similarity

---

### ğŸ§¬ Indexer (LLM Embeddings + Ball Tree)

#### 1. Embedding Generation

- Converts documents to dense vectors
- Uses `mean` pooling

#### 2. Indexing

- Processes in batches
- Stores embeddings in a Ball Tree

#### 3. Search

- Embeds query
- Finds top-k nearest documents
- Returns documents with corresponding distances (scores)

#### Strengths

- Handles semantic similarity
- Recognizes paraphrasing and related terms

---

### ğŸ¤– RAG (Retrieval-Augmented Generation)

#### 1. Prompt Engineering

- Restricts answers to context (fetched Python documents)
- Requires citations
- Forbids unsourced info and code

#### 2. Modes

- **Streaming**: Live response with time/data metrics
- **Batch**: Instant complete answers with error handling

#### 3. Retrieval Process

1. Find top-k nearest documents using indexer
2. Build context using the found documents
3. Combine context with user query
4. Pass to LLM with source tracking

#### 4. LLM Handling

- Async/sync client support
- Streaming + rate limiting
- Error and timeout handling

#### Key Features

- Python-only responses
- JSON-formatted streaming output

---

## ğŸš§ Challenges & Solutions

| Problem                           | Solution/Status                                                                    |
| --------------------------------- | ---------------------------------------------------------------------------------- |
| Word2Vec indexer was not accurate | Switched to LLM embeddings                                                         |
| Local LLM too slow or heavy       | Switched to free hosted APIs ([g4f](https://github.com/xtekky/gpt4free/tree/main)) |
| Poor spelling correction          | Added Norvig-based spell corrector                                                 |

---

## ğŸŒŸ Feature Comparison

| Approach         | Technologies                          | Advantages                                                                       |
| ---------------- | ------------------------------------- | -------------------------------------------------------------------------------- |
| Inverted Index   | Inverted Index + Levenshtein distance | High speed, exact match, lightweight                                             |
| Embedding Search | LLM Embeddings + Ball Tree            | Resilient to synonyms and phrasing                                               |
| RAG              | API + Prompt Engineering              | Multi-source synthesis, deep answers, citation-based, filters irrelevant content |
